{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Практика 4\n",
        "\n",
        "На этой практике мы попробуем описанную в лекции LSTM - это не очень приятно, но мы справимся :)\n",
        "\n",
        "p.s. рекомендуем на этой практике включить ГПУ - это поможет. Для этого жмем \"среда выполнения\" -> сменить среду выполнения, выбираем там T4 GPU\n",
        "\n",
        "Для начала делаем что? Копируем гит:"
      ],
      "metadata": {
        "id": "i2yJMKOVgGb6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B55Cc3XpgDEm"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ArChanDDD/TS-MCSSirius-2024.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "Idwdd1SdgRU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM\n",
        "\n",
        "Если вдруг захочется почитать побольше - есть класная статейка на [хабре](https://habr.com/ru/companies/wunderfund/articles/331310/)"
      ],
      "metadata": {
        "id": "S7dU2pJOgev4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/TS-MCSSirius-2024/data/DailyDelhiClimateTrain.csv')\n",
        "df['date'] = [datetime.strptime(x, '%Y-%m-%d') for x in list(df['date'])]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "48cVKdycgTnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Посмотрим че у нас уже есть\n",
        "train_df = df[:-130]\n",
        "test_df = df[-130:]\n",
        "_, _ = plt.subplots(1, 1, figsize=(20,10))\n",
        "_ = plt.plot(train_df['date'], train_df['meantemp'])\n",
        "_ = plt.plot(test_df['date'], test_df['meantemp'])"
      ],
      "metadata": {
        "id": "e8HjYuVygxqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подготовка датасета\n",
        "\n",
        "В PyTorch операции происходят не с обычными листами или массивами, а с особыми - их называют Тензоры.\n",
        "\n",
        "Наша задача - сделать"
      ],
      "metadata": {
        "id": "KMgZERtOpaSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def create_dataset(dataset, lookback, is_test=False):\n",
        "    X, y = [], []\n",
        "    if not is_test:\n",
        "        for i in range(len(dataset)-lookback):\n",
        "            feature = dataset[i:i+lookback]\n",
        "            target = dataset[i+1:i+lookback+1]\n",
        "            X.append(feature)\n",
        "            y.append(target)\n",
        "    else:\n",
        "        for i in range(len(train_df) - lookback, len(dataset)-lookback):\n",
        "              feature = dataset[i:i+lookback]\n",
        "              target = dataset[i+1:i+lookback+1]\n",
        "              X.append(feature)\n",
        "              y.append(target)\n",
        "    return torch.tensor(X), torch.tensor(y)"
      ],
      "metadata": {
        "id": "87n02txpgpem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lookback = 20\n",
        "\n",
        "X_train, y_train = create_dataset(list(train_df['meantemp']), lookback=lookback)\n",
        "X_test, y_test = create_dataset(list(df['meantemp']), lookback=lookback, is_test=True)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "nvWXuHqggaYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Определим модель"
      ],
      "metadata": {
        "id": "W9gh2JyPCSg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class AirModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lstm = nn.LSTM(input_size=lookback, hidden_size=64, num_layers=4, batch_first=True)\n",
        "        self.linear = nn.Linear(64, 1)\n",
        "    def forward(self, x):\n",
        "        x, _ = self.lstm(x)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "USv-kw76hjxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### И обучим ее!"
      ],
      "metadata": {
        "id": "Nfk_4q05CUgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = AirModel().to(device)\n",
        "X_train = X_train.to(device)\n",
        "X_test = X_test.to(device)\n",
        "y_train = y_train.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.MSELoss()\n",
        "loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=32)\n",
        "\n",
        "n_epochs = 1000\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    for X_batch, y_batch in loader:\n",
        "        y_pred = model(X_batch)\n",
        "        loss = loss_fn(y_pred, y_batch)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    # Validation\n",
        "    if epoch % 100 != 0:\n",
        "        continue\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(X_train)\n",
        "        train_rmse = np.sqrt(loss_fn(y_pred.cpu(), y_train.cpu()))\n",
        "        y_pred = model(X_test)\n",
        "        test_rmse = np.sqrt(loss_fn(y_pred.cpu(), y_test.cpu()))\n",
        "    print(\"Epoch %d: train RMSE %.4f, test RMSE %.4f\" % (epoch, train_rmse, test_rmse))"
      ],
      "metadata": {
        "id": "Hbx9d7SQhxvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Не совсем честное предсказание"
      ],
      "metadata": {
        "id": "sfD5H-mDk0ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_len = len(test_df)\n",
        "\n",
        "test_inputs = train_df['meantemp'][-lookback:].tolist()\n",
        "print(test_inputs)"
      ],
      "metadata": {
        "id": "xGS2121Dh38u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "seq = X_train\n",
        "\n",
        "for i in range(forecast_len):\n",
        "    #seq = torch.vstack((seq, torch.Tensor(test_inputs[-lookback:]).reshape(1, -1).to(device)))\n",
        "    seq = torch.vstack((seq, X_test[i]))\n",
        "    with torch.no_grad():\n",
        "        test_inputs.append(model(seq)[-1].item())\n",
        "\n",
        "forecasted = test_inputs[lookback:]"
      ],
      "metadata": {
        "id": "-hK6HbQcBicA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pred(y_pred):\n",
        "  _, _ = plt.subplots(1, 1, figsize=(20,10))\n",
        "  _ = plt.plot(train_df['date'], train_df['meantemp'], label='train')\n",
        "  _ = plt.plot(test_df['date'], test_df['meantemp'], label='val')\n",
        "  _ = plt.plot(test_df['date'], list(y_pred), label='pred')\n",
        "  _ = plt.legend()"
      ],
      "metadata": {
        "id": "RhohrQsBlrtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred(forecasted)"
      ],
      "metadata": {
        "id": "v8IdUb-bnDmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y_pred):\n",
        "  return np.mean((np.array(test_df['meantemp']) - np.array(y_pred)) ** 2)"
      ],
      "metadata": {
        "id": "N44UFRw3nart"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse(forecasted)"
      ],
      "metadata": {
        "id": "sLslCuWYoacP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### А теперь честное"
      ],
      "metadata": {
        "id": "-MjpkgTEC97r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forecast_len = len(test_df)\n",
        "\n",
        "test_inputs = train_df['meantemp'][-lookback:].tolist()\n",
        "print(test_inputs)"
      ],
      "metadata": {
        "id": "OV4gIIzCC8SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "seq = X_train\n",
        "\n",
        "for i in range(forecast_len):\n",
        "    seq = torch.vstack((seq, torch.Tensor(test_inputs[-lookback:]).reshape(1, -1).to(device)))\n",
        "    with torch.no_grad():\n",
        "        test_inputs.append(model(seq)[-1].item())\n",
        "\n",
        "forecasted = test_inputs[lookback:]"
      ],
      "metadata": {
        "id": "RYwWjHs-C8SB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_pred(y_pred):\n",
        "  _, _ = plt.subplots(1, 1, figsize=(20,10))\n",
        "  _ = plt.plot(train_df['date'], train_df['meantemp'], label='train')\n",
        "  _ = plt.plot(test_df['date'], test_df['meantemp'], label='val')\n",
        "  _ = plt.plot(test_df['date'], list(y_pred), label='pred')\n",
        "  _ = plt.legend()"
      ],
      "metadata": {
        "id": "rr06kgmZC8SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_pred(forecasted)"
      ],
      "metadata": {
        "id": "DfEtJi3bC8SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse(forecasted)"
      ],
      "metadata": {
        "id": "hNFy2PMmC8SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что с этим делать - вам уже решать. Можно докрутить модельку, чтобы она предсказывала на генерируемых данных чуть лучше. А можно переписать процесс генерации и получить выход чуть получше :)"
      ],
      "metadata": {
        "id": "zLnCgXPkDBJc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NT7DNffsDiXQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}